{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 News Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('/Users/qlin/Desktop/sp500_focus_sources_1_23_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64492 unique entries in the \"summary\" column.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique 'content' values among the entire dataset\n",
    "unique_entries = news_df['summary'].nunique()\n",
    "print(f'There are {unique_entries} unique entries in the \"summary\" column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The deduplicated DataFrame has 64493 rows.\n"
     ]
    }
   ],
   "source": [
    "# Drop the duplicated rows but keep the first occurence of each unique 'summary' value based on 'addDate' column\n",
    "# First, sort the DataFrame by 'addDate'\n",
    "df_sorted = news_df.sort_values('addDate')\n",
    "\n",
    "# Then, drop duplicates based on 'content', keeping the first occurrence\n",
    "df_dedup = df_sorted.drop_duplicates(subset='summary', keep='first')\n",
    "\n",
    "# Check the number of rows in the deduplicated DataFrame\n",
    "print(f'The deduplicated DataFrame has {df_dedup.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Filtering SP100 News Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Assume df_dedup is your DataFrame containing deduplicated news articles\n",
    "\n",
    "# Step 1: Load the top 100 companies' tickers\n",
    "with open('Data/Top_100_Companies_Tickers.txt', 'r') as file:\n",
    "    top_100_tickers = file.read().splitlines()\n",
    "\n",
    "# Step 2: Modify the function\n",
    "def contains_top_100_company(companies_str):\n",
    "    companies = ast.literal_eval(companies_str)  # Convert the string to a list\n",
    "    for company in companies:\n",
    "        if any(ticker in company['symbols'] for ticker in top_100_tickers):\n",
    "            return True  # Return True if any of the top 100 companies' tickers is found\n",
    "    return False  # Return False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33925 news articles related to the top 100 companies.\n"
     ]
    }
   ],
   "source": [
    "# Select rows where 'symbols' contains any of the top 100 companies' tickers\n",
    "df_top_100 = df_dedup[df_dedup['companies'].apply(contains_top_100_company)]\n",
    "\n",
    "print(f'There are {len(df_top_100)} news articles related to the top 100 companies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only this columns: 'addDate', 'title', 'description', 'content', 'keywords', 'topics', 'entities', 'companies', 'summary'\n",
    "news_top_100 = df_top_100[['addDate', 'title', 'entities', 'companies', 'summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Find the Main Company Per News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_companies_and_symbols(companies_str, top_100_tickers):\n",
    "    companies = ast.literal_eval(companies_str)\n",
    "    result = []\n",
    "    for company in companies:\n",
    "        matching_symbols = [symbol for symbol in company['symbols'] if symbol in top_100_tickers]\n",
    "        if matching_symbols:\n",
    "            result.append({'name': company['name'], 'symbols': matching_symbols})\n",
    "    return result\n",
    "\n",
    "with open('Data/Top_100_Companies_Tickers.txt', 'r') as file:\n",
    "    top_100_tickers = file.read().splitlines()\n",
    "    \n",
    "# Apply the function to the 'companies' column\n",
    "news_top_100['comp_ticker'] = news_top_100['companies'].apply(lambda x: extract_companies_and_symbols(x, top_100_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Market Capitalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Electronic Technology</td>\n",
       "      <td>2728017215293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>2351371643107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>1611856497958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>1610343852181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>1366884251763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>AMT</td>\n",
       "      <td>American Tower Corporation (REIT)</td>\n",
       "      <td>Finance</td>\n",
       "      <td>82187878166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>CB</td>\n",
       "      <td>Chubb Limited</td>\n",
       "      <td>Finance</td>\n",
       "      <td>82105914715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>CI</td>\n",
       "      <td>The Cigna Group</td>\n",
       "      <td>Health Services</td>\n",
       "      <td>81693476157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>C</td>\n",
       "      <td>Citigroup, Inc.</td>\n",
       "      <td>Finance</td>\n",
       "      <td>81360929490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>BDX</td>\n",
       "      <td>Becton, Dickinson and Company</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>79399811792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Ticker                        Description  \\\n",
       "0            1   AAPL                         Apple Inc.   \n",
       "1            2   MSFT              Microsoft Corporation   \n",
       "2            3   GOOG                      Alphabet Inc.   \n",
       "3            4  GOOGL                      Alphabet Inc.   \n",
       "4            5   AMZN                   Amazon.com, Inc.   \n",
       "..         ...    ...                                ...   \n",
       "95          96    AMT  American Tower Corporation (REIT)   \n",
       "96          97     CB                      Chubb Limited   \n",
       "97          98     CI                    The Cigna Group   \n",
       "98          99      C                    Citigroup, Inc.   \n",
       "99         100    BDX      Becton, Dickinson and Company   \n",
       "\n",
       "                   Sector  Market Capitalization  \n",
       "0   Electronic Technology          2728017215293  \n",
       "1     Technology Services          2351371643107  \n",
       "2     Technology Services          1611856497958  \n",
       "3     Technology Services          1610343852181  \n",
       "4            Retail Trade          1366884251763  \n",
       "..                    ...                    ...  \n",
       "95                Finance            82187878166  \n",
       "96                Finance            82105914715  \n",
       "97        Health Services            81693476157  \n",
       "98                Finance            81360929490  \n",
       "99      Health Technology            79399811792  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_company = pd.read_csv(\"Data/Top_100_Companies.csv\")\n",
    "top_100_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mentions(comp_ticker, entities):\n",
    "    mentions = {company['name']: 0 for company in comp_ticker}\n",
    "    entity_counts = {}\n",
    "    ''' \n",
    "    creates a dictionary mentions that maps each company name to a mention count of 0. Then, it iterates over the entities. \n",
    "    If an entity is of type 'ORG', it checks if the entity data is a substring of a company name or is in the company's symbols. \n",
    "    If it is, it updates the mention count for that company in the mentions dictionary with the maximum of the current mention count and the entity's mention count.\n",
    "    '''\n",
    "    # Normalize company names and symbols for comparison\n",
    "    def normalize_name(name):\n",
    "        return name.lower().replace('.', '').replace(',', '').replace('inc', '').replace('corp', '').strip()\n",
    "\n",
    "    # Collect mentions counts for normalization\n",
    "    for entity in entities:\n",
    "        normalized_entity = normalize_name(entity['data'])\n",
    "        entity_counts[normalized_entity] = entity['mentions']\n",
    "\n",
    "    # Attempt to match entities to companies more flexibly\n",
    "    for company in comp_ticker:\n",
    "        company_name_normalized = normalize_name(company['name'])\n",
    "        potential_matches = [company_name_normalized] + [normalize_name(symbol) for symbol in company['symbols']]\n",
    "        \n",
    "        # Initialize a list to store all matched mention counts\n",
    "        matched_mentions = []\n",
    "\n",
    "        for entity, count in entity_counts.items():\n",
    "            # Check for direct match or if the entity name is a substring of the company name\n",
    "            if entity in potential_matches or any(entity in match for match in potential_matches):\n",
    "                matched_mentions.append(count)\n",
    "                \n",
    "        # If there are matched mentions, set the company's mentions to the highest one\n",
    "        if matched_mentions:\n",
    "            mentions[company['name']] = max(matched_mentions)\n",
    "        # Otherwise, keep the default 0 value\n",
    "\n",
    "    return mentions\n",
    "\n",
    "# Given 'comp_ticker' and 'entities', apply the function\n",
    "comp_ticker = [{'name': 'The Boeing Company', 'symbols': ['BA']}]\n",
    "entities = [{'data': 'Boeing', 'type': 'ORG', 'mentions': 9}, {'data': 'NYSE', 'type': 'ORG', 'mentions': 1}, {'data': 'Bank of America', 'type': 'ORG', 'mentions': 2}, {'data': 'Susquehanna Financial Group', 'type': 'ORG', 'mentions': 3}, {'data': 'Morgan Stanley', 'type': 'ORG', 'mentions': 1}, {'data': '737 MAX', 'type': 'PRODUCT', 'mentions': 6}, {'data': '787', 'type': 'PRODUCT', 'mentions': 4}, {'data': 'Dreamliners', 'type': 'PRODUCT', 'mentions': 1}, {'data': 'Ronald Epstein', 'type': 'PERSON', 'mentions': 2}, {'data': 'Charles Minervino', 'type': 'PERSON', 'mentions': 1}]\n",
    "\n",
    "# Calculate mentions\n",
    "mentions = calculate_mentions(comp_ticker, entities)\n",
    "mentions\n",
    "\n",
    "# Apply the function to the 'comp_ticker' and 'entities' columns\n",
    "news_top_100['mentions'] = news_top_100.apply(lambda row: calculate_mentions(row['comp_ticker'], row['entities']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_top_100 = news_top_100[['addDate', 'title', 'entities', 'summary','parse_companies', 'comp_ticker', 'mentions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "news_top_100.to_csv('/Users/qlin/Desktop/news_top_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected function to handle ties without duplicating non-tie rows\n",
    "def expand_rows_with_ties(news_top_100):\n",
    "    expanded_data = []\n",
    "\n",
    "    for index, row in news_top_100.iterrows():\n",
    "        max_mentions = max(row['mentions'].values())\n",
    "        tied_companies = [company for company, mentions in row['mentions'].items() if mentions == max_mentions]\n",
    "        \n",
    "        if len(tied_companies) > 1:\n",
    "            # If there's a tie, duplicate the row for each company involved in the tie\n",
    "            for company in tied_companies:\n",
    "                new_row = row.copy()\n",
    "                new_row['main_com'] = company\n",
    "                expanded_data.append(new_row)\n",
    "        else:\n",
    "            # If there's no tie, just append the row as it is\n",
    "            new_row = row.copy()\n",
    "            new_row['main_com'] = tied_companies[0] if tied_companies else None\n",
    "            expanded_data.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(expanded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36406"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now apply the function to your DataFrame\n",
    "expanded_df = expand_rows_with_ties(news_top_100)\n",
    "len(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the expanded DataFrame alphabetically by the 'main_com' column\n",
    "expanded_df['addDate'] = pd.to_datetime(expanded_df['addDate'])\n",
    "\n",
    "expanded_news = expanded_df.sort_values(by=['main_com', 'addDate'], ascending=[True, True]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the data from 2023-01-01 to 2023-12-31 based on addDate column\n",
    "expanded_news_limted = expanded_news[(expanded_news['addDate'] >= '2023-01-01') & \n",
    "                              (expanded_news['addDate'] <= '2023-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_news_limted = expanded_news_limted[['addDate', 'title', 'summary', 'main_com']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/t2ddpfgd6gs899m17rdgm2vc0000gn/T/ipykernel_20936/3637714785.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  expanded_news_limted['Month'] = expanded_news_limted['addDate'].dt.strftime('%B')\n"
     ]
    }
   ],
   "source": [
    "# add a Month column to the expanded_news_limted DataFrame based on the 'addDate' column\n",
    "expanded_news_limted['Month'] = expanded_news_limted['addDate'].dt.strftime('%B')\n",
    "\n",
    "# save to csv\n",
    "expanded_news_limted.to_csv('/Users/qlin/Desktop/expanded_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Using GPT to Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addDate</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>main_com</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-01-03 17:05:09.585710+00:00</td>\n",
       "      <td>AT&amp;T Inc. (T) Is a Trending Stock: Facts to Kn...</td>\n",
       "      <td>And if earnings estimates go up for a company,...</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-01-04 20:00:50.317817+00:00</td>\n",
       "      <td>AT&amp;T rises as CFO Pascal says fiber join ventu...</td>\n",
       "      <td>AT&amp;T rises as CFO Pascal says fiber join ventu...</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-01-05 12:22:49.284029+00:00</td>\n",
       "      <td>1 Top Dividend Stock to Buy for 2023 and Beyond</td>\n",
       "      <td>1 Top Dividend Stock to Buy for 2023 and Beyon...</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023-01-05 20:09:04.026523+00:00</td>\n",
       "      <td>The Best Investing Advice for 2023</td>\n",
       "      <td>\\n\\nEvery week, host and Zacks stock strategis...</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-01-08 13:08:33.480586+00:00</td>\n",
       "      <td>Top Picks 2023- ATT T</td>\n",
       "      <td>Management raised the mid-point of its 2022 ea...</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36401</th>\n",
       "      <td>2023-11-26 12:32:35.545066+00:00</td>\n",
       "      <td>Is Zoetis (NYSE:ZTS) Using Too Much Debt?</td>\n",
       "      <td>Zoetis Inc. (NYSE:ZTS) is using too much debt ...</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36402</th>\n",
       "      <td>2023-12-12 16:28:12.516179+00:00</td>\n",
       "      <td>The Zacks Analyst Blog Highlights Invitation H...</td>\n",
       "      <td>Zacks.com has highlighted five stocks featured...</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36403</th>\n",
       "      <td>2023-12-14 10:19:55.065065+00:00</td>\n",
       "      <td>Zoetis' (NYSE:ZTS) Upcoming Dividend Will Be L...</td>\n",
       "      <td>Zoetis Inc.'s (NYSE:ZTS) will increase its div...</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36404</th>\n",
       "      <td>2023-12-22 12:24:57.671503+00:00</td>\n",
       "      <td>Is Now The Time To Put Zoetis (NYSE:ZTS) On Yo...</td>\n",
       "      <td>Zoetis (NYSE:ZTS) has been growing its earning...</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36405</th>\n",
       "      <td>2023-12-30 11:17:14.109727+00:00</td>\n",
       "      <td>Is Zoetis (NYSE:ZTS) A Risky Investment?</td>\n",
       "      <td>Zoetis Inc. (NYSE:ZTS) carries debt, which can...</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30862 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               addDate  \\\n",
       "42    2023-01-03 17:05:09.585710+00:00   \n",
       "43    2023-01-04 20:00:50.317817+00:00   \n",
       "44    2023-01-05 12:22:49.284029+00:00   \n",
       "45    2023-01-05 20:09:04.026523+00:00   \n",
       "46    2023-01-08 13:08:33.480586+00:00   \n",
       "...                                ...   \n",
       "36401 2023-11-26 12:32:35.545066+00:00   \n",
       "36402 2023-12-12 16:28:12.516179+00:00   \n",
       "36403 2023-12-14 10:19:55.065065+00:00   \n",
       "36404 2023-12-22 12:24:57.671503+00:00   \n",
       "36405 2023-12-30 11:17:14.109727+00:00   \n",
       "\n",
       "                                                   title  \\\n",
       "42     AT&T Inc. (T) Is a Trending Stock: Facts to Kn...   \n",
       "43     AT&T rises as CFO Pascal says fiber join ventu...   \n",
       "44       1 Top Dividend Stock to Buy for 2023 and Beyond   \n",
       "45                    The Best Investing Advice for 2023   \n",
       "46                                 Top Picks 2023- ATT T   \n",
       "...                                                  ...   \n",
       "36401          Is Zoetis (NYSE:ZTS) Using Too Much Debt?   \n",
       "36402  The Zacks Analyst Blog Highlights Invitation H...   \n",
       "36403  Zoetis' (NYSE:ZTS) Upcoming Dividend Will Be L...   \n",
       "36404  Is Now The Time To Put Zoetis (NYSE:ZTS) On Yo...   \n",
       "36405           Is Zoetis (NYSE:ZTS) A Risky Investment?   \n",
       "\n",
       "                                                 summary     main_com  \\\n",
       "42     And if earnings estimates go up for a company,...    AT&T Inc.   \n",
       "43     AT&T rises as CFO Pascal says fiber join ventu...    AT&T Inc.   \n",
       "44     1 Top Dividend Stock to Buy for 2023 and Beyon...    AT&T Inc.   \n",
       "45     \\n\\nEvery week, host and Zacks stock strategis...    AT&T Inc.   \n",
       "46     Management raised the mid-point of its 2022 ea...    AT&T Inc.   \n",
       "...                                                  ...          ...   \n",
       "36401  Zoetis Inc. (NYSE:ZTS) is using too much debt ...  Zoetis Inc.   \n",
       "36402  Zacks.com has highlighted five stocks featured...  Zoetis Inc.   \n",
       "36403  Zoetis Inc.'s (NYSE:ZTS) will increase its div...  Zoetis Inc.   \n",
       "36404  Zoetis (NYSE:ZTS) has been growing its earning...  Zoetis Inc.   \n",
       "36405  Zoetis Inc. (NYSE:ZTS) carries debt, which can...  Zoetis Inc.   \n",
       "\n",
       "          Month  \n",
       "42      January  \n",
       "43      January  \n",
       "44      January  \n",
       "45      January  \n",
       "46      January  \n",
       "...         ...  \n",
       "36401  November  \n",
       "36402  December  \n",
       "36403  December  \n",
       "36404  December  \n",
       "36405  December  \n",
       "\n",
       "[30862 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_news_limted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29495"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expanded_news_limted data exclude main_com = AT&T Inc.\tAbbVie, Abbott Laboratories,Accenture plc, Adobe Inc., Advanced Micro Devices, Inc.\n",
    "expanded_news_limted_exclude = expanded_news_limted[~expanded_news_limted['main_com'].isin(['AT&T Inc.', 'AbbVie Inc.', 'Abbott Laboratories','Accenture plc', 'Adobe Inc.', 'Advanced Micro Devices, Inc.'])]\n",
    "len(expanded_news_limted_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addDate</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>main_com</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>2023-01-02 16:30:20.260512+00:00</td>\n",
       "      <td>Big Tech will ‘have a better year’ in 2023, an...</td>\n",
       "      <td>\\n\\nThough it's been a bleak year for the sect...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>2023-01-03 10:47:55.766191+00:00</td>\n",
       "      <td>2 Remarkable Growth Stocks Set to Soar in 2023...</td>\n",
       "      <td>2 Remarkable Growth Stocks Set to Soar in 2023...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>2023-01-03 15:28:22.933077+00:00</td>\n",
       "      <td>Alphabet (GOOGL) Enhances Google Home App With...</td>\n",
       "      <td>Alphabet (GOOGL) Enhances Google Home App With...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>2023-01-03 16:46:08.645001+00:00</td>\n",
       "      <td>Alphabet (GOOGL) Ups YouTube Efforts, Boosts G...</td>\n",
       "      <td>Alphabet (GOOGL) Ups YouTube Efforts, Boosts G...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>2023-01-03 16:53:14.148248+00:00</td>\n",
       "      <td>Wall Street Bulls Look Optimistic About Alphab...</td>\n",
       "      <td>According to several studies, brokerage recomm...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2023-12-29 13:03:33.061477+00:00</td>\n",
       "      <td>Quiet Markets, Ugly Treasury Auction, Fed's Ag...</td>\n",
       "      <td>The S&amp;P 500 gained less than two points or 0.0...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2023-12-29 15:44:06.969417+00:00</td>\n",
       "      <td>If You Invested $1000 in Alphabet a Decade Ago...</td>\n",
       "      <td>Alphabet (GOOGL) is one of the most innovative...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2023-12-29 15:52:36.569663+00:00</td>\n",
       "      <td>UCLA Wants to Buy Google’s Westside Pavilion O...</td>\n",
       "      <td>UCLA is reportedly planning to buy a former sh...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>2023-12-29 21:41:09.130704+00:00</td>\n",
       "      <td>'Trillion-dollar club' companies reach combine...</td>\n",
       "      <td>The combined market cap of US companies valued...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>2023-12-29 21:54:32.079124+00:00</td>\n",
       "      <td>These Stocks Moved the Most Today: Lyft, Uber,...</td>\n",
       "      <td>Lyft stock fell 3.5% to $14.99 after Nomura an...</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              addDate  \\\n",
       "1807 2023-01-02 16:30:20.260512+00:00   \n",
       "1808 2023-01-03 10:47:55.766191+00:00   \n",
       "1809 2023-01-03 15:28:22.933077+00:00   \n",
       "1810 2023-01-03 16:46:08.645001+00:00   \n",
       "1811 2023-01-03 16:53:14.148248+00:00   \n",
       "...                               ...   \n",
       "2997 2023-12-29 13:03:33.061477+00:00   \n",
       "2998 2023-12-29 15:44:06.969417+00:00   \n",
       "2999 2023-12-29 15:52:36.569663+00:00   \n",
       "3000 2023-12-29 21:41:09.130704+00:00   \n",
       "3001 2023-12-29 21:54:32.079124+00:00   \n",
       "\n",
       "                                                  title  \\\n",
       "1807  Big Tech will ‘have a better year’ in 2023, an...   \n",
       "1808  2 Remarkable Growth Stocks Set to Soar in 2023...   \n",
       "1809  Alphabet (GOOGL) Enhances Google Home App With...   \n",
       "1810  Alphabet (GOOGL) Ups YouTube Efforts, Boosts G...   \n",
       "1811  Wall Street Bulls Look Optimistic About Alphab...   \n",
       "...                                                 ...   \n",
       "2997  Quiet Markets, Ugly Treasury Auction, Fed's Ag...   \n",
       "2998  If You Invested $1000 in Alphabet a Decade Ago...   \n",
       "2999  UCLA Wants to Buy Google’s Westside Pavilion O...   \n",
       "3000  'Trillion-dollar club' companies reach combine...   \n",
       "3001  These Stocks Moved the Most Today: Lyft, Uber,...   \n",
       "\n",
       "                                                summary       main_com  \\\n",
       "1807  \\n\\nThough it's been a bleak year for the sect...  Alphabet Inc.   \n",
       "1808  2 Remarkable Growth Stocks Set to Soar in 2023...  Alphabet Inc.   \n",
       "1809  Alphabet (GOOGL) Enhances Google Home App With...  Alphabet Inc.   \n",
       "1810  Alphabet (GOOGL) Ups YouTube Efforts, Boosts G...  Alphabet Inc.   \n",
       "1811  According to several studies, brokerage recomm...  Alphabet Inc.   \n",
       "...                                                 ...            ...   \n",
       "2997  The S&P 500 gained less than two points or 0.0...  Alphabet Inc.   \n",
       "2998  Alphabet (GOOGL) is one of the most innovative...  Alphabet Inc.   \n",
       "2999  UCLA is reportedly planning to buy a former sh...  Alphabet Inc.   \n",
       "3000  The combined market cap of US companies valued...  Alphabet Inc.   \n",
       "3001  Lyft stock fell 3.5% to $14.99 after Nomura an...  Alphabet Inc.   \n",
       "\n",
       "         Month  \n",
       "1807   January  \n",
       "1808   January  \n",
       "1809   January  \n",
       "1810   January  \n",
       "1811   January  \n",
       "...        ...  \n",
       "2997  December  \n",
       "2998  December  \n",
       "2999  December  \n",
       "3000  December  \n",
       "3001  December  \n",
       "\n",
       "[1195 rows x 5 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect only 'Alphabet Inc.' data from expanded_news_limted_exclude\n",
    "expanded_news_limted_exclude_Alphabet = expanded_news_limted_exclude[expanded_news_limted_exclude['main_com'] == 'Alphabet Inc.']\n",
    "expanded_news_limted_exclude_Alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'main_com' and 'month'\n",
    "grouped = expanded_news_limted_exclude_Alphabet.groupby(['main_com', 'Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library\n",
    "from openai._client import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "key = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# instantiate the OpenAI client\n",
    "client = OpenAI(api_key=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate summaries using GPT-4\n",
    "def generate_summary(client, company, news_summaries):\n",
    "\n",
    "    # Define the system persona\n",
    "    systemPersona = \"You are an expert in finance and the technology industry.\"\n",
    "\n",
    "    # Generate the prompt\n",
    "    user_message = f\"\"\"\n",
    "    As an expert in technology and financial industry news, your task is to distill key information from a collection of monthly news article summaries about a specific company. \n",
    "    You will provide a brief, integrated summary that captures the essence of the company's activities, milestones, and market presence during the month.\n",
    "\n",
    "    The company in focus for this month's synthesis is {company}. Below are the key points extracted from news articles over the past month:\n",
    "\n",
    "    {news_summaries}\n",
    "\n",
    "    Please amalgamate this information into a comprehensive summary that includes:\n",
    "\n",
    "    - Major events or announcements made by the company\n",
    "    - Noteworthy financial occurrences or business dealings\n",
    "    - Any significant changes in the company's strategy or market standing\n",
    "    - Public or investor sentiment if mentioned in the articles\n",
    "\n",
    "    Your summary should provide a clear overview of the company's news footprint for the month, highlighting any developments that could have a lasting impact on the company's trajectory.\n",
    "\n",
    "    Generate a comprehensive summary no more than 150 words, ensuring it is succinct yet thorough enough to inform stakeholders of the company's monthly news highlights.\n",
    "\n",
    "    Rely only on the details provided from the news summaries without incorporating external information.\n",
    "    \"\"\"\n",
    "    # Call the API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": systemPersona},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    # Return the summary provided by GPT-4\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the summaries into a new DataFrame\n",
    "summary_records = []\n",
    "\n",
    "for (company, month), group in grouped:\n",
    "    # Concatenate all summaries for the company and month\n",
    "    all_summaries = \" \".join(group['summary'].tolist())\n",
    "    # Generate the summary with GPT-4\n",
    "    monthly_summary = generate_summary(client, company, all_summaries)\n",
    "    # Append to the summary records\n",
    "    summary_records.append({\n",
    "        'company': company,\n",
    "        'month': month,\n",
    "        'monthly_summary': monthly_summary\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the summary records\n",
    "summary_df = pd.DataFrame(summary_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>month</th>\n",
       "      <th>monthly_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>April</td>\n",
       "      <td>AT&amp;T Inc. faced potential market disruption bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>August</td>\n",
       "      <td>AT&amp;T Inc. recently increased the monthly charg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>December</td>\n",
       "      <td>Over the past month, AT&amp;T Inc. announced major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>February</td>\n",
       "      <td>AT&amp;T has had a mixed month with various import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>January</td>\n",
       "      <td>AT&amp;T, through its partnership with BlackRock, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Advanced Micro Devices, Inc.</td>\n",
       "      <td>March</td>\n",
       "      <td>Advanced Micro Devices, Inc. (AMD) has had a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Advanced Micro Devices, Inc.</td>\n",
       "      <td>May</td>\n",
       "      <td>Advanced Micro Devices (AMD) released its Q1 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Advanced Micro Devices, Inc.</td>\n",
       "      <td>November</td>\n",
       "      <td>Advanced Micro Devices (AMD) experienced mixed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Advanced Micro Devices, Inc.</td>\n",
       "      <td>October</td>\n",
       "      <td>Advanced Micro Devices (AMD) experienced a rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Advanced Micro Devices, Inc.</td>\n",
       "      <td>September</td>\n",
       "      <td>Advanced Micro Devices, Inc. (AMD) saw varied ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         company      month  \\\n",
       "0                      AT&T Inc.      April   \n",
       "1                      AT&T Inc.     August   \n",
       "2                      AT&T Inc.   December   \n",
       "3                      AT&T Inc.   February   \n",
       "4                      AT&T Inc.    January   \n",
       "..                           ...        ...   \n",
       "67  Advanced Micro Devices, Inc.      March   \n",
       "68  Advanced Micro Devices, Inc.        May   \n",
       "69  Advanced Micro Devices, Inc.   November   \n",
       "70  Advanced Micro Devices, Inc.    October   \n",
       "71  Advanced Micro Devices, Inc.  September   \n",
       "\n",
       "                                      monthly_summary  \n",
       "0   AT&T Inc. faced potential market disruption bu...  \n",
       "1   AT&T Inc. recently increased the monthly charg...  \n",
       "2   Over the past month, AT&T Inc. announced major...  \n",
       "3   AT&T has had a mixed month with various import...  \n",
       "4   AT&T, through its partnership with BlackRock, ...  \n",
       "..                                                ...  \n",
       "67  Advanced Micro Devices, Inc. (AMD) has had a n...  \n",
       "68  Advanced Micro Devices (AMD) released its Q1 r...  \n",
       "69  Advanced Micro Devices (AMD) experienced mixed...  \n",
       "70  Advanced Micro Devices (AMD) experienced a rob...  \n",
       "71  Advanced Micro Devices, Inc. (AMD) saw varied ...  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp6 = pd.read_csv(\"/Users/qlin/Desktop/summary.csv\")\n",
    "comp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine com6 and summary_df\n",
    "combined = pd.concat([comp6, summary_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order\n",
    "months_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Convert the 'month' column to a categorical type\n",
    "combined['month'] = pd.Categorical(combined['month'], categories=months_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by the 'month' column but keep the 'company\n",
    "combined = combined.sort_values(by=['company', 'month']).reset_index(drop=True)\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "combined = combined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('/Users/qlin/Desktop/summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
