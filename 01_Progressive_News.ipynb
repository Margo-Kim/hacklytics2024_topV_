{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 News Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('/Users/qlin/Desktop/sp500_focus_sources_1_23_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64492 unique entries in the \"summary\" column.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique 'content' values among the entire dataset\n",
    "unique_entries = news_df['summary'].nunique()\n",
    "print(f'There are {unique_entries} unique entries in the \"summary\" column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The deduplicated DataFrame has 64493 rows.\n"
     ]
    }
   ],
   "source": [
    "# Drop the duplicated rows but keep the first occurence of each unique 'summary' value based on 'addDate' column\n",
    "# First, sort the DataFrame by 'addDate'\n",
    "df_sorted = news_df.sort_values('addDate')\n",
    "\n",
    "# Then, drop duplicates based on 'content', keeping the first occurrence\n",
    "df_dedup = df_sorted.drop_duplicates(subset='summary', keep='first')\n",
    "\n",
    "# Check the number of rows in the deduplicated DataFrame\n",
    "print(f'The deduplicated DataFrame has {df_dedup.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Filtering SP100 News Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Assume df_dedup is your DataFrame containing deduplicated news articles\n",
    "\n",
    "# Step 1: Load the top 100 companies' tickers\n",
    "with open('Data/Top_100_Companies_Tickers.txt', 'r') as file:\n",
    "    top_100_tickers = file.read().splitlines()\n",
    "\n",
    "# Step 2: Modify the function\n",
    "def contains_top_100_company(companies_str):\n",
    "    companies = ast.literal_eval(companies_str)  # Convert the string to a list\n",
    "    for company in companies:\n",
    "        if any(ticker in company['symbols'] for ticker in top_100_tickers):\n",
    "            return True  # Return True if any of the top 100 companies' tickers is found\n",
    "    return False  # Return False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33925 news articles related to the top 100 companies.\n"
     ]
    }
   ],
   "source": [
    "# Select rows where 'symbols' contains any of the top 100 companies' tickers\n",
    "df_top_100 = df_dedup[df_dedup['companies'].apply(contains_top_100_company)]\n",
    "\n",
    "print(f'There are {len(df_top_100)} news articles related to the top 100 companies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only this columns: 'addDate', 'title', 'description', 'content', 'keywords', 'topics', 'entities', 'companies', 'summary'\n",
    "news_top_100 = df_top_100[['addDate', 'title', 'entities', 'companies', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_top_100.to_csv('/Users/qlin/Desktop/news_top_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/t2ddpfgd6gs899m17rdgm2vc0000gn/T/ipykernel_20936/1101133659.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_top_100['parse_companies'] = news_top_100['companies'].apply(parse_company)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def parse_company(company_str): \n",
    "    '''\n",
    "    function to parse the company string and return a list of companies\n",
    "    '''\n",
    "    try:\n",
    "        # Try to parse the string as JSON\n",
    "        companies = json.loads(company_str.replace(\"'\", \"\\\"\"))\n",
    "        # Extract the 'name' field from each topic\n",
    "        return [company['name'] for company in companies]\n",
    "    except json.JSONDecodeError:\n",
    "        # If the string is not valid JSON, return an empty list\n",
    "        return []\n",
    "\n",
    "news_top_100['parse_companies'] = news_top_100['companies'].apply(parse_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Market Capitalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Electronic Technology</td>\n",
       "      <td>2728017215293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>2351371643107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>1611856497958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>1610343852181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>1366884251763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>AMT</td>\n",
       "      <td>American Tower Corporation (REIT)</td>\n",
       "      <td>Finance</td>\n",
       "      <td>82187878166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>CB</td>\n",
       "      <td>Chubb Limited</td>\n",
       "      <td>Finance</td>\n",
       "      <td>82105914715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>CI</td>\n",
       "      <td>The Cigna Group</td>\n",
       "      <td>Health Services</td>\n",
       "      <td>81693476157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>C</td>\n",
       "      <td>Citigroup, Inc.</td>\n",
       "      <td>Finance</td>\n",
       "      <td>81360929490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>BDX</td>\n",
       "      <td>Becton, Dickinson and Company</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>79399811792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Ticker                        Description  \\\n",
       "0            1   AAPL                         Apple Inc.   \n",
       "1            2   MSFT              Microsoft Corporation   \n",
       "2            3   GOOG                      Alphabet Inc.   \n",
       "3            4  GOOGL                      Alphabet Inc.   \n",
       "4            5   AMZN                   Amazon.com, Inc.   \n",
       "..         ...    ...                                ...   \n",
       "95          96    AMT  American Tower Corporation (REIT)   \n",
       "96          97     CB                      Chubb Limited   \n",
       "97          98     CI                    The Cigna Group   \n",
       "98          99      C                    Citigroup, Inc.   \n",
       "99         100    BDX      Becton, Dickinson and Company   \n",
       "\n",
       "                   Sector  Market Capitalization  \n",
       "0   Electronic Technology          2728017215293  \n",
       "1     Technology Services          2351371643107  \n",
       "2     Technology Services          1611856497958  \n",
       "3     Technology Services          1610343852181  \n",
       "4            Retail Trade          1366884251763  \n",
       "..                    ...                    ...  \n",
       "95                Finance            82187878166  \n",
       "96                Finance            82105914715  \n",
       "97        Health Services            81693476157  \n",
       "98                Finance            81360929490  \n",
       "99      Health Technology            79399811792  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_company = pd.read_csv(\"Data/Top_100_Companies.csv\")\n",
    "top_100_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Inc.': 'AAPL',\n",
       " 'Microsoft Corporation': 'MSFT',\n",
       " 'Alphabet Inc.': 'GOOGL',\n",
       " 'Amazon.com, Inc.': 'AMZN',\n",
       " 'NVIDIA Corporation': 'NVDA',\n",
       " 'Berkshire Hathaway Inc. New': 'BRK.B',\n",
       " 'Meta Platforms, Inc.': 'META',\n",
       " 'Tesla, Inc.': 'TSLA',\n",
       " 'Eli Lilly and Company': 'LLY',\n",
       " 'Visa Inc.': 'V',\n",
       " 'UnitedHealth Group Incorporated': 'UNH',\n",
       " 'Johnson & Johnson': 'JNJ',\n",
       " 'Exxon Mobil Corporation': 'XOM',\n",
       " 'JP Morgan Chase & Co.': 'JPM',\n",
       " 'Walmart Inc.': 'WMT',\n",
       " 'Mastercard Incorporated': 'MA',\n",
       " 'Procter & Gamble Company (The)': 'PG',\n",
       " 'Broadcom Inc.': 'AVGO',\n",
       " 'Home Depot, Inc. (The)': 'HD',\n",
       " 'Oracle Corporation': 'ORCL',\n",
       " 'Chevron Corporation': 'CVX',\n",
       " 'Merck & Company, Inc.': 'MRK',\n",
       " 'AbbVie Inc.': 'ABBV',\n",
       " 'Coca-Cola Company (The)': 'KO',\n",
       " 'PepsiCo, Inc.': 'PEP',\n",
       " 'Costco Wholesale Corporation': 'COST',\n",
       " 'Adobe Inc.': 'ADBE',\n",
       " 'Bank of America Corporation': 'BAC',\n",
       " 'Cisco Systems, Inc.': 'CSCO',\n",
       " 'Pfizer, Inc.': 'PFE',\n",
       " 'Thermo Fisher Scientific Inc': 'TMO',\n",
       " 'McDonald’s Corporation': 'MCD',\n",
       " 'Accenture plc': 'ACN',\n",
       " 'Salesforce, Inc.': 'CRM',\n",
       " 'Comcast Corporation': 'CMCSA',\n",
       " 'Danaher Corporation': 'DHR',\n",
       " 'Linde plc': 'LIN',\n",
       " 'Abbott Laboratories': 'ABT',\n",
       " 'Netflix, Inc.': 'NFLX',\n",
       " 'Advanced Micro Devices, Inc.': 'AMD',\n",
       " 'Nike, Inc.': 'NKE',\n",
       " 'T-Mobile US, Inc.': 'TMUS',\n",
       " 'Walt Disney Company (The)': 'DIS',\n",
       " 'Wells Fargo & Company': 'WFC',\n",
       " 'Texas Instruments Incorporated': 'TXN',\n",
       " 'Philip Morris International Inc': 'PM',\n",
       " 'United Parcel Service, Inc.': 'UPS',\n",
       " 'Morgan Stanley': 'MS',\n",
       " 'ConocoPhillips': 'COP',\n",
       " 'Amgen Inc.': 'AMGN',\n",
       " 'Caterpillar, Inc.': 'CAT',\n",
       " 'Verizon Communications Inc.': 'VZ',\n",
       " 'Union Pacific Corporation': 'UNP',\n",
       " 'NextEra Energy, Inc.': 'NEE',\n",
       " 'Intel Corporation': 'INTC',\n",
       " 'Boeing Company (The)': 'BA',\n",
       " 'Intuit Inc.': 'INTU',\n",
       " 'Bristol-Myers Squibb Company': 'BMY',\n",
       " 'International Business Machines Corporation': 'IBM',\n",
       " 'Lowe’s Companies, Inc.': 'LOW',\n",
       " 'RTX Corporation': 'RTX',\n",
       " 'Honeywell International Inc.': 'HON',\n",
       " 'QUALCOMM Incorporated': 'QCOM',\n",
       " 'General Electric Company': 'GE',\n",
       " 'S&P Global Inc.': 'SPGI',\n",
       " 'Applied Materials, Inc.': 'AMAT',\n",
       " 'American Express Company': 'AXP',\n",
       " 'Deere & Company': 'DE',\n",
       " 'Prologis, Inc.': 'PLD',\n",
       " 'Lockheed Martin Corporation': 'LMT',\n",
       " 'Starbucks Corporation': 'SBUX',\n",
       " 'ServiceNow, Inc.': 'NOW',\n",
       " 'Booking Holdings Inc. Common Stock': 'BKNG',\n",
       " 'Elevance Health, Inc.': 'ELV',\n",
       " 'Medtronic plc.': 'MDT',\n",
       " 'Charles Schwab Corporation (The)': 'SCHW',\n",
       " 'Goldman Sachs Group, Inc. (The)': 'GS',\n",
       " 'Stryker Corporation': 'SYK',\n",
       " 'Automatic Data Processing, Inc.': 'ADP',\n",
       " 'TJX Companies, Inc. (The)': 'TJX',\n",
       " 'Intuitive Surgical, Inc.': 'ISRG',\n",
       " 'AT&T Inc.': 'T',\n",
       " 'BlackRock, Inc.': 'BLK',\n",
       " 'Mondelez International, Inc.': 'MDLZ',\n",
       " 'Gilead Sciences, Inc.': 'GILD',\n",
       " 'Marsh & McLennan Companies, Inc.': 'MMC',\n",
       " 'Vertex Pharmaceuticals Incorporated': 'VRTX',\n",
       " 'Analog Devices, Inc.': 'ADI',\n",
       " 'Regeneron Pharmaceuticals, Inc.': 'REGN',\n",
       " 'Lam Research Corporation': 'LRCX',\n",
       " 'CVS Health Corporation': 'CVS',\n",
       " 'Eaton Corporation, PLC': 'ETN',\n",
       " 'Zoetis Inc.': 'ZTS',\n",
       " 'Schlumberger N.V.': 'SLB',\n",
       " 'American Tower Corporation (REIT)': 'AMT',\n",
       " 'Chubb Limited': 'CB',\n",
       " 'The Cigna Group': 'CI',\n",
       " 'Citigroup, Inc.': 'C',\n",
       " 'Becton, Dickinson and Company': 'BDX'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from company descriptions to tickers\n",
    "description_to_ticker = pd.Series(top_100_company.Ticker.values, index=top_100_company.Description).to_dict()\n",
    "description_to_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/t2ddpfgd6gs899m17rdgm2vc0000gn/T/ipykernel_20936/1874158048.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_top_100['mentions'] = df_top_100.apply(lambda row: calculate_mentions(row['parse_companies'], row['entities']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "def calculate_mentions(companies, entities):\n",
    "    '''\n",
    "    checks if each entity name from entities is a substring of the company name from parse_companies. \n",
    "    If it is, it increments the mention count for that company.\n",
    "    '''\n",
    "    mentions = {company: 0 for company in companies}\n",
    "    for entity in entities:\n",
    "        if entity['type'] == 'ORG':\n",
    "            for company in companies:\n",
    "                if entity['data'] in company:\n",
    "                    mentions[company] += entity['mentions']\n",
    "    return mentions\n",
    "\n",
    "df_top_100['mentions'] = df_top_100.apply(lambda row: calculate_mentions(row['parse_companies'], row['entities']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are not yet tested code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage(mentions):\n",
    "    total_mentions = sum(mentions.values())\n",
    "    return {company: (count / total_mentions) * 100 for company, count in mentions.items()}\n",
    "\n",
    "df_top_100['percentage'] = df_top_100['mentions'].apply(calculate_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_company(percentage):\n",
    "    return max(percentage, key=percentage.get)\n",
    "\n",
    "df_top_100['main_company'] = df_top_100['percentage'].apply(find_main_company)\n",
    "df_top_100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
